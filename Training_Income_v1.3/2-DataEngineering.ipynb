{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Data engineering and wrangling\n",
    "1. Read in dataset\n",
    "2. Clean / encode dataset \n",
    "3. Save dataset back into project repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Loading student variable\n",
    "%store -r STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectRepo(path):\n",
    "   ProjectRepo = \"/bd-fs-mnt/project_repo\"\n",
    "   return str(ProjectRepo + '/' + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's view our dataset to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ProjectRepo('data/' + STUDENT + '_UCI_Income/adult_data.csv')\n",
    "test_file = ProjectRepo('data/' + STUDENT + '_UCI_Income/adult_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(train_file, header=None)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(test_file, skiprows=1, header=None)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Findings\n",
    "1. No column headers (can fix using dataset description from website)\n",
    "2. Some \"?\" in test data \n",
    "3. Target values differ in train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Fix column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Clean up ? in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.replace(' ?', np.nan).dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.replace(' ?', np.nan).dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with \"?\" from our dataframes \n",
    "train_no_missing = train_set.replace(' ?', np.nan).dropna()\n",
    "test_no_missing = test_set.replace(' ?', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fix targets (remove the extra periods from '<=50K.' to '<=50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_missing['wage_class'] = test_no_missing.wage_class.replace({' <=50K.' : ' <=50K', ' >50K.' : ' >50K'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_missing.wage_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_missing.wage_class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying ordinal encoding to categoricals\n",
    "- ordinal encoding: convert string labels to integer values 1 through k. First unique value in column becomes 1, the second becomes 2, the third becomes 3, and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the datasets together first\n",
    "combined_set = pd.concat([train_no_missing, test_no_missing], axis=0)\n",
    "combined_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations after initial cleaning of dataset \n",
    "group = combined_set.groupby('wage_class')\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode non-numerical features into numeric values using pandas Cateogrical codes \n",
    "#and generating categorical codes mapping into dictionary\n",
    "cat_codes = {}\n",
    "for feature in combined_set.columns: \n",
    "    if combined_set[feature].dtype == 'object':\n",
    "        #workclass : { occupation : number }\n",
    "        temp_dict = {}\n",
    "        feature_codes = list(pd.Categorical(combined_set[feature]).codes)\n",
    "        feature_list = list(combined_set[feature])\n",
    "        for i in range(len(feature_codes)):\n",
    "            temp_dict[feature_list[i].strip()] = int(feature_codes[i])\n",
    "            if len(temp_dict) > len(feature_list):\n",
    "                break\n",
    "        cat_codes[feature] = temp_dict\n",
    "        combined_set[feature] = pd.Categorical(combined_set[feature]).codes\n",
    "combined_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving encoding to json file to be used for scoring script\n",
    "json_file = ProjectRepo('data/' + STUDENT + '_UCI_Income/encoding.json')\n",
    "with open(json_file, 'w') as file:\n",
    "    json.dump(cat_codes, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split combined set back into test/train split \n",
    "final_train = combined_set[:train_no_missing.shape[0]] \n",
    "final_test = combined_set[train_no_missing.shape[0]:]\n",
    "final_train.to_csv(ProjectRepo('data/' + STUDENT + '_UCI_Income/adult_train_cleaned.csv'))\n",
    "final_test.to_csv(ProjectRepo('data/' + STUDENT + '_UCI_Income/adult_test_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue onto Lab 3 for modeling! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
