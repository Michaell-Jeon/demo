{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8608fbe-233e-466e-ac3f-ad19fdce1bb5",
   "metadata": {},
   "source": [
    "# Lab 3 Modeling \n",
    "1. Define a model \n",
    "2. Experiment and hyper parameter tuning\n",
    "3. Train model on training cluster\n",
    "4. Save model back into project repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523c1e9-0477-49fd-ba88-ef5b350de195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random as ran\n",
    "from datetime import datetime \n",
    "import os\n",
    "\n",
    "%store -r STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da62b4-0dc2-4cf6-96bd-fe613f97eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Project repo path function - file system mount available to all app containers\n",
    "def ProjectRepo(path):\n",
    "    ProjectRepo = \"/bd-fs-mnt/project_repo\"\n",
    "    return str(ProjectRepo + '/' + path)\n",
    "\n",
    "# Locations of mnist data   \n",
    "MNIST_LOC = ProjectRepo(\"/data/\" + STUDENT + \"_MNIST/mnist.npz\")\n",
    "\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data(path=MNIST_LOC)\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bdc078-f0ba-446d-b978-9e6f244dd697",
   "metadata": {},
   "source": [
    "# Before running the next couple cells for training, please shut down all other kernels to free up resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b08ece-25d4-47a5-824c-d4b620bca2f4",
   "metadata": {},
   "source": [
    "# Model Development 1 \n",
    "- defining a small model to train on 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cac79-e2c1-49bc-92e7-96730ac7efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "TrainstartTime = datetime.now()\n",
    "model.fit(train_images, train_labels, epochs=2)\n",
    "\n",
    "TrainendTime = datetime.now()\n",
    "print(\"\\nTraining Time:\", TrainendTime - TrainstartTime)\n",
    "\n",
    "print(\"\\nEvaluate Test Images:\")\n",
    "EvalstartTime = datetime.now()\n",
    "\n",
    "#model.evaluate(test_images, test_labels)\n",
    "EvalendTime = datetime.now()\n",
    "print(\"\\nEvaluate Time:\", EvalendTime - EvalstartTime)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5eeb37-9df4-43c4-a9a1-e083cf9027f8",
   "metadata": {},
   "source": [
    "# Model Development 2 \n",
    "- introducing batch size variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dabcc-e6e5-46da-bfa3-a539ecbfe190",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128  \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "TrainstartTime = datetime.now()\n",
    "model.fit(train_images, train_labels, epochs=2,batch_size=BATCH_SIZE)\n",
    "\n",
    "TrainendTime = datetime.now()\n",
    "print(\"\\nTraining Time:\", TrainendTime - TrainstartTime)\n",
    "\n",
    "print(\"\\nEvaluate Test Images:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88fce4-06a4-4914-81c4-9e715d0c1319",
   "metadata": {},
   "source": [
    "## Train the model on the remote shared training cluster\n",
    "\n",
    "In general, data scientists use their local Jupyter Notebook to **experiment** several learning algorithms with a variety of parameters. They do so to determine the ML model that works best for the business problem they try to address and develop the model that yields to the best prediction result. Then, within their notebooks, they submit their code to large scaled computing training cluster environment to train and test their full ML models, in a reasonable time, typically against a larger training dataset and test dataset. The output of this step is a trained model ready for deployment in production.\n",
    "\n",
    ">**Note:** _This workshop is not intended to teach you about AI/ML model experimentation and development. It is intended to give a use case for data science end-to-end ML workflow with HPE Ezmeral ML Ops. Therefore we will assume that the experimentation step has already been done and that the data science team has shared the best performant ML model in a notebook in the GitHub version control system repository set up by the Operations team for the data science team. The notebook is actually this notebook pulled from GitHub repository by the local Jupyter Notebook cluster. Here you will submit the ML model code to the tenant-shared training cluster environment to train and test your model against the train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66250a-2cb9-41c9-b8b0-d5e743af9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "%attachments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945f938-632d-4e58-898a-f5ef9a220fc6",
   "metadata": {},
   "source": [
    "## Here we will train on 5 epochs\n",
    "- Don't forget to fill in your <b>STUDENT</b> variable and your training cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66150c-75e2-4f3c-b053-8910a6da9308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%training\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random as ran\n",
    "from datetime import datetime \n",
    "import os\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "STUDENT = \"\"\n",
    "\n",
    "# Project repo path function - file system mount available to all app containers\n",
    "def ProjectRepo(path):\n",
    "    ProjectRepo = \"/bd-fs-mnt/project_repo/\"\n",
    "    return str(ProjectRepo + '/' + path)\n",
    "\n",
    "# Locations of mnist data   \n",
    "MNIST_LOC = ProjectRepo(\"/data/\" + STUDENT + \"_MNIST/mnist.npz\")\n",
    "\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data(path=MNIST_LOC)\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "BATCH_SIZE = 128  \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "TrainstartTime = datetime.now()\n",
    "model.fit(train_images, train_labels, epochs=5,batch_size=BATCH_SIZE)\n",
    "\n",
    "TrainendTime = datetime.now()\n",
    "print(\"\\nTraining Time:\", TrainendTime - TrainstartTime)\n",
    "\n",
    "print(\"\\nEvaluate Test Images:\")\n",
    "\n",
    "#save model in h5 format\n",
    "model.save(ProjectRepo('models/' + STUDENT + '_MNIST/mnist_digits.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365b6e7-b8d8-4d5c-9121-c6319cf001f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the history url from the output of the previous cell\n",
    "%logs --url <your history url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a6ba-6032-490a-bb89-5725ae0650d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
